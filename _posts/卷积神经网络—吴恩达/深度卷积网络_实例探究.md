### 经典卷积网络

1. LeNet

![](https://ws1.sinaimg.cn/large/acbcfa39gy1g37v4izsefj210s0kegoe.jpg)

2. AlexNet

![](https://ws1.sinaimg.cn/large/acbcfa39gy1g37v5xe67cj21190ketc0.jpg)

3. VGG-16（16 指的是该网络架构中卷积层和全连接层的个数总和）

![](https://ws1.sinaimg.cn/large/acbcfa39gy1g37v74ew5oj21120kljuy.jpg)

三篇论文的阅读顺序：2-3-1

### ResNets

深的网络，会导致**梯度消失**和**梯度爆炸**

- Residual block（残差块）ResNets 网络是由许多残差块构成的

![](https://ws1.sinaimg.cn/large/acbcfa39gy1g37vixk68zj210m0kctba.jpg)

- 有了残差神经网络使得训练更深的网络成为可能，训练的错误也会降低

![](https://ws1.sinaimg.cn/large/acbcfa39gy1g37vku3z9fj210m0k9gpb.jpg)